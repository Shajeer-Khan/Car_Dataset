####    AT FIRST DATASET    ####

1. Data Preparation
Loading the Dataset: The data have been loaded into a Pandas DataFrame.
Feature Selection: Features were selected as independent variables (X), and the dependent variable (likely engine RPM) was chosen as y.
Data Splitting: The data was split into training and testing sets using train_test_split, with a specific test size (often 20-30%) and a random state for reproducibility.

2. Model Implementation
The following regression models were implemented:

Linear Regression:
The linear regression model was fitted to the training data (X_train and y_train).
Predictions were made on the testing data (X_test).

Random Forest Regression:
A random forest model was built using multiple decision trees.
The model’s predictions were generated, and results were stored for comparison.

3. Model Evaluation
Performance Metrics: Metrics such as Mean Squared Error (MSE) were calculated for each model. These metrics help assess the accuracy and consistency of the predictions.
Comparison: The models compared based on the above metrics to determine which one performed best.

4. Visualization
Scatter plots were generated to compare actual vs. predicted values for each model.
A line representing perfect predictions (diagonal line) was plotted to visualize deviations in predictions.
A grid and legend were included for better interpretation.

####    AT SECOND DATASET    ####

1. Dataset Loading and Exploration
Loaded the dataset using pandas to analyze its structure.
Checked for missing values and understood column types.
Identified potential target and feature columns for analysis.
Purpose: This helps understand the structure of the dataset, identify columns with missing data, and get a first look at the content.

2. Data Cleaning and Preprocessing
Dropped columns with too many missing values:
Threshold: Columns with more than 50% missing values were removed.
Imputed missing values:
Remaining missing values were filled with the mean of each column.
Removed non-informative columns:
Columns like IDs, timestamps, and constant columns with no variation were dropped.
Purpose: Cleaning the data ensures that the dataset is ready for analysis, with no significant missing or irrelevant values.

3. Exploratory Data Analysis (EDA)
Correlation Heatmap:
Plotted a heatmap to analyze how features correlate with each other and with the target variable.
Scatter Plot Check:
We created scatter plots to visualize relationships between individual features and the target variable.
Purpose:
The heatmap identifies features that are strongly correlated with the target.
Scatter plots help to check the relationship type (linear/non-linear), which informs model choice.

4. Feature and Target Selection
Selected the target column (vehicle_speed in this case).
Defined the remaining columns as features.
Purpose: This step sets up the data for training the machine learning model.

5. Train-Test Split
Split the dataset into training and testing sets.
Used an 80-20 split: 80% for training, 20% for testing.
Purpose: Splitting ensures that the model is trained on one subset of data and tested on another unseen subset to check performance.

6. Model Training: Random Forest
Trained a Random Forest Regressor model, a robust machine learning algorithm suitable for non-linear and complex relationships.
Why Random Forest?:
Random Forest handles non-linearity, missing values, and feature interactions well.
It reduces overfitting by averaging multiple decision trees.

7. Model Prediction and Evaluation
Predicted the target variable on the test set.
Calculated Mean Squared Error (MSE) to measure model performance.
Purpose: MSE is a standard metric to evaluate regression models. A lower MSE indicates better predictions.

8. Actual vs Predicted Scatter Plot
Plotted a scatter plot of actual vs predicted values with a red line showing "perfect predictions."
Purpose:
The closer the points are to the red line, the better the model's predictions.
This plot visually evaluates the model's accuracy.

####    AT THIRD DATASET    ####

1. Data Cleaning
Handling Missing Values:
Columns with more than 50% missing values were identified and dropped.
Remaining missing values in numerical columns were filled with the column's mean.
Dropping Irrelevant Columns:
Columns such as bulk_id, car_reg_no, time_stamp, latitude, and longitude were deemed irrelevant and removed from the dataset.

2. Exploratory Data Analysis (EDA)
Correlation Heatmap:
A heatmap of the correlation matrix was generated to visualize relationships between numerical variables.
Distribution Plots:
Histograms were created for key numerical features: vehicle_speed, engine_rpm, calculated_engine_load, and mass_air_flow_rate.
Scatter Plots:
Relationships between vehicle_speed and other key features were analyzed through scatter plots.

3. Feature Selection
The target variable was identified as vehicle_speed.
Remaining columns were used as features.

4. Data Splitting
The data was split into training and testing sets (80% training, 20% testing) using train_test_split.

5. Data Standardization
Features were standardized using StandardScaler to improve model performance.

6. Model Training
Linear Regression Model:
Trained using the standardized training data.
Performance was evaluated using RMSE (Root Mean Squared Error) and R² score.

Random Forest Regressor:
Trained as an alternative model to compare results with Linear Regression.
Similar performance metrics (RMSE and R² score) were calculated.

7. Model Evaluation
Linear Regression Results:
RMSE: 11.639
R² Score: 0.573
Accuracy: 57.29%

Random Forest Results:
RMSE: 7.227
R² Score: 0.835
Accuracy: 83.53%
Visualization:
Scatter plots of actual vs. predicted vehicle_speed were created for both models.

####    AT FOURTH DATASET    ####

1. Data Overview
Explored the dataset with .head(), .info(), and .describe() to understand its structure, including 41 columns and 31,671 rows.

2. Missing Data Analysis
Identified columns with a significant amount of missing values.
Dropped columns with more than 50% missing data and imputed missing values in the remaining columns with their mean for numerical features.

3. Data Cleaning
Removed irrelevant columns like bulk_id, car_reg_no, and time_stamp.

4. Exploratory Data Analysis (EDA):
a. Feature Distribution
Visualized the distributions of various features using histograms to understand their spread.

b. Correlation Analysis
Computed and visualized the correlation matrix to identify relationships among variables.

5. Predictive Modeling:
a. Target and Features
Defined the target variable (vehicle_speed) and independent features.

b. Data Splitting
Split the data into training and testing sets (80% training and 20% testing).

c. Feature Scaling
Standardized the features using StandardScaler for better performance in machine learning models.

d. Model Training
Used a RandomForestRegressor to predict vehicle speed.
Trained the model with 100 estimators and a random state of 0.

5. Model Evaluation:
a. Predictions
Predicted the vehicle speed on the test set.

b. Performance Metrics
Evaluated the model using:
Root Mean Squared Error (RMSE): 7.80
R-squared (R²): 0.8013 (80.13% of variance explained).

c. Visual Analysis
Compared actual vs. predicted values with scatter plots.
Highlighted the ideal fit line.

6. Feature Importance:
Visualized the importance of each feature in the prediction model.
Identified critical predictors like throttle position and engine load.

